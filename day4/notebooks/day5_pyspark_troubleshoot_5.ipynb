{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5일차 5교시 - Spark Bucketing\n",
    "> 스파크에서 버킷팅 기법이란 조인 혹은 집계 연산 시에 가장 성능을 떨어뜨리는 셔플을 피하기 위해 저장 시에 예상되는 파티션 그룹 키를 기반으로 미리 그룹핑 해서 저장해 두는 방법을 말합니다. spark.sql.sources.bucketing.enabled 를 통해 제어할 수 있고 기본 설정은 true 입니다. 결국 저장 시에 추가적인 고민과 시간이 필요하다는 의미이며, 그렇게 해서라도 충분히 리소스 사용을 상쇄할 수 있다고 판단되는 경우에만 사용하는 것을 추천 드립니다. Write Once Read Many 인 경우가 그러합니다.\n",
    "\n",
    "### 목차\n",
    "* 1. '버킷팅'이란?\n",
    "* 2. 언제 '버킷팅'을 적용하는가?\n",
    "* 3. '버킷팅' 다루기\n",
    "* 4. References\n",
    "  * https://luminousmen.com/post/the-5-minute-guide-to-using-bucketing-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data Engineer Intermediate Day4\") \\\n",
    "    .config(\"spark.dataengineer.intermediate.day4\", \"troubleshoot-5\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. '버킷팅'이란?\n",
    "> 하둡 기반의 파일 저장구조를 활용하는 스파크의 경우 세컨더리 인덱스 지원이 어렵기 때문에 '파티셔닝'을 통해 필터하는 것에는 한계가 있기 마련입니다. 이러한 문제를 해결하기 위해 버킷팅이라는 기법을 활용할 수 있는데, 특정 키와 파티션 수를 기준으로 대상 파티션 경로 내에 또 다른 파티션 파일 블록의 저장을 통해 읽기 성능을 최적화 시킬 수 있는데, 반드시 하이브/스파크 테이블 형태로만 저장된다는 점에 유의해야만 합니다.\n",
    "이는 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 언제 '버킷팅'을 적용하는가?\n",
    "* 디멘젼과 같은 누적 형식의 테이블의 경우 셔플이 발생하는 경우\n",
    "  * 조인 혹은 집계 대상이 되는 모든 데이터가 노드 간에 전달이 되기 때문에 네트워크 및 I/O 리소스를 많이 잡아 먹어 성능에 큰 영향을 미칩니다\n",
    "* 대용량 데이터의 셔플에 의한 익스큐터 노드의 저장데이터가 커지는 경우를 회피\n",
    "  * 익스큐터가 수행되는 노드의 임시 경로에 많은 데이터를 담게되므로 물리 노드에 부하를 주게되어 해당 노드에서 수행되는 다른 작업에도 영향이 있으며 클러스터 전체적인 성능 저하를 가져올 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. '버킷팅' 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. 그대로 저장 시에는 전체 셔플이 발생합니다.\n",
    "![bucket1](image/bucket-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- engine_size: decimal(38,18) (nullable = true)\n",
      " |-- registration: string (nullable = true)\n",
      " |-- sale_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = spark.read.parquet(\"source/t1\")\n",
    "s2 = spark.read.parquet(\"source/t2\")\n",
    "c12 = s1.join(s2, [s1.make == s2.make]).select(s1.make, s1.model, s1.engine_size, s1.registration, s2.sale_price)\n",
    "c12.printSchema()\n",
    "# mode(\"append\")\n",
    "# mode(\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 1000000\n"
     ]
    }
   ],
   "source": [
    "c1 = s1.count()\n",
    "c2 = s2.count()\n",
    "print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Project [make#1, model#2, engine_size#3, registration#0, sale_price#11]\n",
      "+- *(2) BroadcastHashJoin [make#1], [make#8], Inner, BuildLeft\n",
      "   :- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, true]))\n",
      "   :  +- *(1) Project [registration#0, make#1, model#2, engine_size#3]\n",
      "   :     +- *(1) Filter isnotnull(make#1)\n",
      "   :        +- *(1) FileScan parquet [registration#0,make#1,model#2,engine_size#3] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/source/t1], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<registration:string,make:string,model:string,engine_size:decimal(38,18)>\n",
      "   +- *(2) Project [make#8, sale_price#11]\n",
      "      +- *(2) Filter isnotnull(make#8)\n",
      "         +- *(2) FileScan parquet [make#8,sale_price#11] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/source/t2], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<make:string,sale_price:double>\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|   make|model|         engine_size|registration|sale_price|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    2046.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    2688.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    3492.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    4723.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    3256.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    2011.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    5457.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    5151.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    4600.0|\n",
      "|HYUNDAI|  I20|1.600000000000000000|     Admxty2|    5373.0|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c12.explain()\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 1*1024*1024)\n",
    "c12.where(\"sale_price > 2000.0\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. 파티션으로 저장 시에는 한쪽 파티션은 필터를 통한 잇점이 있습니다\n",
    "![bucket2](image/bucket-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.write.mode(\"overwrite\").partitionBy(\"make\").parquet(\"target/troubleshoot5/model\")\n",
    "s2.write.mode(\"overwrite\").partitionBy(\"make\").parquet(\"target/troubleshoot5/price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spark.read.parquet(\"target/troubleshoot5/model\")\n",
    "price = spark.read.parquet(\"target/troubleshoot5/price\")\n",
    "model_price = model.join(price, [model.make == price.make]).select(model.make, model.model, model.engine_size, model.registration, price.sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [make#90, model#88, engine_size#89, registration#87, sale_price#97]\n",
      "+- *(5) SortMergeJoin [make#90], [make#98], Inner\n",
      "   :- *(2) Sort [make#90 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(make#90, 200)\n",
      "   :     +- *(1) FileScan parquet [registration#87,model#88,engine_size#89,make#90] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/target/troubleshoot5/model], PartitionCount: 9, PartitionFilters: [isnotnull(make#90)], PushedFilters: [], ReadSchema: struct<registration:string,model:string,engine_size:decimal(38,18)>\n",
      "   +- *(4) Sort [make#98 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(make#98, 200)\n",
      "         +- *(3) FileScan parquet [sale_price#97,make#98] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/target/troubleshoot5/price], PartitionCount: 9, PartitionFilters: [isnotnull(make#98)], PushedFilters: [], ReadSchema: struct<sale_price:double>\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|   make|model|         engine_size|registration|sale_price|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    4315.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    3506.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    4359.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    4483.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    3979.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    2997.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    2294.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    4067.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    3278.0|\n",
      "|HYUNDAI|  I20|1.200000000000000000|     yazBgLK|    3679.0|\n",
      "+-------+-----+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_price.explain()\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 1*1024*1024)\n",
    "model_price.where(\"sale_price > 2000.0\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. 버킷 저장 시에는 셔플이 발생하지 않습니다.\n",
    "![bucket3](image/bucket-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBuckets = 10\n",
    "# 이전에 삭제되지 않은 임시 경로가 있다면 삭제합니다.\n",
    "!rm -rf /home/jovyan/work/spark-warehouse/model\n",
    "!rm -rf /home/jovyan/work/spark-warehouse/price\n",
    "s1.write.mode(\"overwrite\").bucketBy(numBuckets, \"make\").sortBy(\"make\").saveAsTable(\"model\")\n",
    "s2.write.mode(\"overwrite\").bucketBy(numBuckets, \"make\").sortBy(\"make\").saveAsTable(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = spark.sql(\"select * from model\")\n",
    "t2 = spark.sql(\"select * from price\")\n",
    "t12 = t1.join(t2, [t1.make == t2.make]).select(t1.make, t1.model, t1.engine_size, t1.registration, t2.sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [make#185, model#186, engine_size#187, registration#184, sale_price#195]\n",
      "+- *(3) SortMergeJoin [make#185], [make#192], Inner\n",
      "   :- *(1) Sort [make#185 ASC NULLS FIRST], false, 0\n",
      "   :  +- *(1) Project [registration#184, make#185, model#186, engine_size#187]\n",
      "   :     +- *(1) Filter isnotnull(make#185)\n",
      "   :        +- *(1) FileScan parquet default.model[registration#184,make#185,model#186,engine_size#187] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/spark-warehouse/model], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<registration:string,make:string,model:string,engine_size:decimal(38,18)>, SelectedBucketsCount: 10 out of 10\n",
      "   +- *(2) Sort [make#192 ASC NULLS FIRST], false, 0\n",
      "      +- *(2) Project [make#192, sale_price#195]\n",
      "         +- *(2) Filter isnotnull(make#192)\n",
      "            +- *(2) FileScan parquet default.price[make#192,sale_price#195] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/work/spark-warehouse/price], PartitionFilters: [], PushedFilters: [IsNotNull(make)], ReadSchema: struct<make:string,sale_price:double>, SelectedBucketsCount: 10 out of 10\n",
      "+------+-------+--------------------+------------+----------+\n",
      "|  make|  model|         engine_size|registration|sale_price|\n",
      "+------+-------+--------------------+------------+----------+\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    2559.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    3464.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    4174.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    4446.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    3095.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    2049.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    3344.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    4286.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    5349.0|\n",
      "|NISSAN|QASHQAI|1.000000000000000000|     7mHeVRZ|    4149.0|\n",
      "+------+-------+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t12.explain()\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 1*1024*1024)\n",
    "t12.where(\"sale_price > 2000.0\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
